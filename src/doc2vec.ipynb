{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from razdel import sentenize\n",
    "from models.model_builder import AbsSummarizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertData:\n",
    "    def __init__(self, bert_model, lower, max_src_tokens, max_tgt_tokens):\n",
    "        self.max_src_tokens = max_src_tokens\n",
    "        self.max_tgt_tokens = max_tgt_tokens\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=lower, do_basic_tokenize=False)\n",
    "        self.sep_token = '[SEP]'\n",
    "        self.cls_token = '[CLS]'\n",
    "        self.pad_token = '[PAD]'\n",
    "        self.tgt_bos = '[unused1] '\n",
    "        self.tgt_eos = ' [unused2]'\n",
    "        self.tgt_sent_split = ' [unused3] '\n",
    "        self.sep_vid = self.tokenizer.vocab[self.sep_token]\n",
    "        self.cls_vid = self.tokenizer.vocab[self.cls_token]\n",
    "        self.pad_vid = self.tokenizer.vocab[self.pad_token]\n",
    "\n",
    "    def preprocess(self, src, tgt):\n",
    "        src_txt = [' '.join(s) for s in src]\n",
    "        text = ' {} {} '.format(self.sep_token, self.cls_token).join(src_txt)\n",
    "        src_tokens = self.tokenizer.tokenize(text)[:self.max_src_tokens]\n",
    "        src_tokens.insert(0, self.cls_token)\n",
    "        src_tokens.append(self.sep_token)\n",
    "        src_indices = self.tokenizer.convert_tokens_to_ids(src_tokens)\n",
    "\n",
    "        _segs = [-1] + [i for i, t in enumerate(src_indices) if t == self.sep_vid]\n",
    "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
    "        segments_ids = []\n",
    "        for i, s in enumerate(segs):\n",
    "            if i % 2 == 0:\n",
    "                segments_ids += s * [0]\n",
    "            else:\n",
    "                segments_ids += s * [1]\n",
    "\n",
    "        return src_indices, segments_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2bert(text):\n",
    "    src = [s.text.lower().split() for s in sentenize(text)]\n",
    "    src_indices, segments_ids = bert_data.preprocess(src, '')\n",
    "    return { \"src\": src_indices, \"segs\": segments_ids }\n",
    "\n",
    "def doc2vec(text, model, mode='MeanSum'):\n",
    "    doc_bert = doc2bert(text)\n",
    "    \n",
    "    src = torch.tensor([doc_bert['src']])\n",
    "    segs = torch.tensor([doc_bert['segs']])\n",
    "    mask_src = ~(src == 0)\n",
    "    \n",
    "    output = model.bert(src, segs, mask_src)\n",
    "    \n",
    "    if mode == 'FirstCLS':\n",
    "        return output[0][0]\n",
    "    elif mode == 'MeanSum':\n",
    "        return output[0].mean(0)\n",
    "    else:\n",
    "        raise Exception('Wrong mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/data/alolbuhtijarov/rubert_cased_L-12_H-768_A-12_pt/model_step_55000.pt',\n",
    "                        map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = lambda a: b\n",
    "\n",
    "args.model_path = '/data/alolbuhtijarov/rubert_cased_L-12_H-768_A-12_pt'\n",
    "args.large = False\n",
    "args.temp_dir = 'temp'\n",
    "args.finetune_bert = False\n",
    "args.encoder = 'bert'\n",
    "args.max_pos = 256\n",
    "args.dec_layers = 6\n",
    "args.share_emb = False\n",
    "args.dec_hidden_size = 768\n",
    "args.dec_heads = 8\n",
    "args.dec_ff_size = 2048\n",
    "args.dec_dropout = 0.2\n",
    "args.use_bert_emb = False\n",
    "\n",
    "bert_data = BertData(args.model_path, True, 510, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbsSummarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2)\n",
       "    )\n",
       "    (transformer_layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (generator): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=119547, bias=True)\n",
       "    (1): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AbsSummarizer(args, 'cpu', checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_markup(file_name):\n",
    "    with open(file_name, \"r\") as r:\n",
    "        reader = csv.reader(r, delimiter='\\t', quotechar='\"')\n",
    "        header = next(reader)\n",
    "        for row in reader:\n",
    "            assert len(header) == len(row)\n",
    "            record = dict(zip(header, row))\n",
    "            yield record\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def calc_metrics(gold_markup, url2label, url2record, output_dict=False):\n",
    "    not_found_count = 0\n",
    "    for first_url, second_url in list(gold_markup.keys()):\n",
    "        not_found_in_labels = first_url not in url2label or second_url not in url2label\n",
    "        not_found_in_records = first_url not in url2record or second_url not in url2record\n",
    "        if not_found_in_labels or not_found_in_records:\n",
    "            not_found_count += 1\n",
    "            gold_markuo.pop((first_url, second_url))\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    for (first_url, second_url), target in gold_markup.items():\n",
    "        prediction = int(url2label[first_url] == url2label[second_url])\n",
    "        first = url2record.get(first_url)\n",
    "        second = url2record.get(second_url)\n",
    "        targets.append(target)\n",
    "        predictions.append(prediction)\n",
    "    return classification_report(targets, predictions, output_dict=output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_path = \"/data/alolbuhtijarov/datasets/ru_threads_target.tsv\"\n",
    "clustering_data_path = \"/data/alolbuhtijarov/datasets/ru_clustering_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup = defaultdict(dict)\n",
    "for record in read_markup(markup_path):\n",
    "    first_url = record[\"INPUT:first_url\"]\n",
    "    second_url = record[\"INPUT:second_url\"]\n",
    "    quality = int(record[\"OUTPUT:quality\"] == \"OK\")\n",
    "    markup[(first_url, second_url)] = quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2record = dict()\n",
    "filename2url = dict()\n",
    "with open(clustering_data_path, \"r\") as r:\n",
    "    for line in r:\n",
    "        record = json.loads(line)\n",
    "        url2record[record[\"url\"]] = record\n",
    "        filename2url[record[\"file_name\"]] = record[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 716/10730 [01:08<15:56, 10.47it/s]"
     ]
    }
   ],
   "source": [
    "embeds = np.zeros((len(url2record), 768))\n",
    "\n",
    "for i, (url, record) in tqdm.tqdm(enumerate(url2record.items()), total=embeds.shape[0]):\n",
    "    text = record[\"title\"] + ' ' + record[\"text\"]\n",
    "    text = text.lower().replace('\\xa0', ' ')\n",
    "    embeds[i] = doc2vec(text, model, mode='MeanSum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality(dist_threshold, print_result=False):\n",
    "    clustering_model = AgglomerativeClustering(n_clusters=None,\n",
    "                                           distance_threshold=dist_threshold,\n",
    "                                           linkage=\"single\",\n",
    "                                           affinity=\"cosine\")\n",
    "\n",
    "    clustering_model.fit(embeds)\n",
    "    labels = clustering_model.labels_\n",
    "    \n",
    "    id2url = dict()\n",
    "    for i, (url, _) in enumerate(url2record.items()):\n",
    "        id2url[i] = url\n",
    "\n",
    "    url2label = dict()\n",
    "    for i, label in enumerate(labels):\n",
    "        url2label[id2url[i]] = label\n",
    "        \n",
    "    if print_result:\n",
    "        print(calc_metrics(markup, url2label, url2record))\n",
    "        return\n",
    "    metrics = calc_metrics(markup, url2label, url2record, output_dict=True)\n",
    "    return metrics['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = np.logspace(-5, 0, 70)\n",
    "quals = [get_quality(dist) for dist in tqdm.tqdm(domain, total=70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(domain, quals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closer_domain = np.linspace(domain[np.argmax(quals)-5], domain[np.argmax(quals)+5], 70)\n",
    "closer_quals = [get_quality(dist) for dist in tqdm.tqdm(closer_domain, total=70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(closer_domain, closer_quals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dist = closer_domain[np.argmax(closer_quals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1571\n",
      "           1       0.77      0.85      0.81      1130\n",
      "\n",
      "    accuracy                           0.83      2701\n",
      "   macro avg       0.83      0.83      0.83      2701\n",
      "weighted avg       0.84      0.83      0.83      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_quality(best_dist, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40k checkpoint; title + ' ' + text; MeanSum, dist = 0.187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      1571\n",
      "           1       0.78      0.83      0.81      1130\n",
      "\n",
      "    accuracy                           0.83      2701\n",
      "   macro avg       0.83      0.83      0.83      2701\n",
      "weighted avg       0.84      0.83      0.84      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_quality(best_dist, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sum",
   "language": "python",
   "name": "env_sum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
